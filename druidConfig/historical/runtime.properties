#
# Druid - a distributed column store.
# Copyright 2012 - 2015 Metamarkets Group Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default host: localhost. Default port: 8083. If you run each node type on its own node in production, you should override these values to be IP:8080
druid.host=nodeHost
druid.port=8080
druid.service=druid:prod:historical


# Our intermediate buffer is also very small so longer topNs will be slow.
# In prod: set sizeBytes = 512mb
#druid.processing.buffer.sizeBytes=314572800
druid.processing.buffer.sizeBytes=536870912
# We can only 1 scan segment in parallel with these configs.
# In prod: set numThreads = # cores - 1
druid.processing.numThreads=15

# maxSize should reflect the performance you want.
# Druid memory maps segments.
# memory_for_segments = total_memory - heap_size - (processing.buffer.sizeBytes * (processing.numThreads+1)) - JVM overhead (~1G)
# The greater the memory/disk ratio, the better performance you should see
druid.segmentCache.locations=[{"path": "/tmp/druid/indexCache", "maxSize"\: 42949672960}]
druid.server.maxSize=42949672960

druid.server.http.numThreads=50

druid.monitoring.monitors=["io.druid.server.metrics.HistoricalMetricsMonitor", "com.metamx.metrics.JvmMonitor"]